{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦ä¸­çš„åº”ç”¨ï¼šæ•°æ®ç§‘å­¦--åŸºç¡€2\n",
    "\n",
    "## Python ç¼–ç¨‹ï¼š\"numpy\" å’Œ \"pandas\"\n",
    "\n",
    "- è®²å¸ˆï¼šitwangyang (itwangyang@gmail.com)\n",
    "\n",
    "- ç›®æ ‡å—ä¼—ï¼šåŒ»å­¦ç”Ÿ\n",
    "\n",
    "- è¯¾ç¨‹æ—¥æœŸï¼š2024 å¹´ 09 æœˆ 13 æ—¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "åœ¨æœ¬æ¬¡å­¦ä¹ ä¸­ï¼Œæ‚¨å°†æ¥è§¦åˆ°**æ•°æ®ç§‘å­¦ã€‚æ‚¨å°†ä½¿ç”¨**Pythonè½¯ä»¶åŒ… \"numpy \"å’Œ \"pandas\"ï¼ŒåŠ è½½å¹¶å¤„ç†COVID-19æ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.å­¦ä¹ ç›®æ ‡\n",
    "#### ç†è®º\n",
    "* æ•°æ®ç§‘å­¦\n",
    "* `numpy` åº“\n",
    "* `pandas`åº“\n",
    "### å®ç”¨\n",
    "- 1.æ•°æ®é›†\n",
    "- 2.ç”¨ `pandas` ä½œä¸º `DataFrame` è¯»å–æ•°æ®\n",
    "- 3.æŸ¥çœ‹æ•°æ®\n",
    "- 4.é€‰æ‹©åˆ—\n",
    "- 5.è·å–åˆ—ä¸­çš„å”¯ä¸€æ¡ç›®\n",
    "- 6.é€‰æ‹©è¡Œ\n",
    "- 7.åˆ†ç»„æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.å‚è€ƒæ–‡çŒ®\n",
    "\n",
    "- æ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½\n",
    "    - http://varianceexplained.org/r/ds-ml-ai/\n",
    "- å‘é‡ã€çŸ©é˜µã€å¼ é‡\n",
    "    - https://www.quantstart.com/articles/scalars-vectors-matrices-and-tensors-linear-algebra-for-deep-learning-part-1/\n",
    "    - https://dev.to/mmithrakumar/scalars-vectors-matrices-and-tensors-with-tensorflow-2-0-1f66\n",
    "- `numpy`\n",
    "    - https://numpy.org/doc/stable/user/absolute_beginners.html\n",
    "    - https://scipy-lectures.org/intro/numpy/array_object.html\n",
    "- `pandas`\n",
    "    - https://medium.com/dunder-data/how-to-learn-pandas-108905ab4955\n",
    "    - https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/#iloc-selection\n",
    "    - https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c\n",
    "- æ•°æ®é›†\n",
    "    - COVID-19 ç—…ä¾‹ï¼š[åŸå§‹ RKI æ•°æ®](https://opendata.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0.csv)\n",
    "    - å¾·å›½ç–«è‹—æ¥ç§è¿›å±•æƒ…å†µï¼š[åŸå§‹ RKI æ•°æ®](https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Daten/Impfquoten-Tab.html) å’Œ[å¤„ç†åæ•°æ®](https://github.com/ard-data/2020-rki-impf-archive)\n",
    "- æ•°æ®å¯è§†åŒ–\n",
    "    - RKI COVID-19 é¢æ¿][https://corona.rki.de/]\n",
    "    - [COVID-19 æŸæ—å„åŒºæ¡ˆä¾‹ > Bezirke > Ãœbersicht](https://www.berlin.de/corona/lagebericht/)\n",
    "    - [ç–«è‹—æ¥ç§ä»ªè¡¨æ¿](https://impfdashboard.de/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.ç†è®º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ•°æ®ç§‘å­¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½ä¹‹é—´æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\n",
    "\n",
    "æ”¹ç¼–è‡ª [David Robinson çš„åšæ–‡](http://varianceexplained.org/r/ds-ml-ai/)ã€‚\n",
    "\n",
    "æ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½é¢†åŸŸç¡®å®æœ‰å¾ˆå¤š***é‡å ä¹‹å¤„ï¼Œä½†å®ƒä»¬***ä¸èƒ½äº’æ¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **æ•°æ®ç§‘å­¦**äº§ç”Ÿ**è§è§£**\n",
    "- \"æ™®é€šæ‚£è€…çš„å­˜æ´»å‡ ç‡ä¸º 70%\"ï¼ˆæè¿°æ€§ï¼šæè¿°æ•°æ®é›†ï¼‰\n",
    "- \"ä¸åŒçš„ç—…äººæœ‰ä¸åŒçš„å­˜æ´»å‡ ç‡\"ï¼ˆæ¢ç´¢æ€§ï¼šå‘ç°ä½ ä¸çŸ¥é“çš„å…³ç³»ï¼‰\n",
    "- éšæœºå®éªŒè¡¨æ˜ï¼Œåˆ†é…ç»™ Alice çš„ç—…äººæ¯”åˆ†é…ç»™ Bob çš„ç—…äººæ›´æœ‰å¯èƒ½å­˜æ´»\"ï¼ˆç›¸å…³æ€§ï¼šæ‰¾å‡ºä¸€ä¸ªå˜é‡åœ¨å¦ä¸€ä¸ªå˜é‡å‘ç”Ÿå˜åŒ–æ—¶çš„æƒ…å†µï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **æœºå™¨å­¦ä¹ **ï¼ˆMLï¼‰äº§ç”Ÿ**é¢„æµ‹**\n",
    "\n",
    "- \"é¢„æµ‹è¿™åæ‚£è€…æ˜¯å¦ä¼šæ‚£ä¸Šè´¥è¡€ç—‡\"\n",
    "- \"é¢„æµ‹è¿™å¼ å›¾ç‰‡ä¸­æ˜¯å¦æœ‰ä¸€åªé¸Ÿ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **äººå·¥æ™ºèƒ½**ï¼ˆAIï¼‰äº§ç”Ÿ**è¡ŒåŠ¨**\n",
    "\n",
    "- æ¸¸æˆç®—æ³•ï¼ˆæ·±è“ã€AlphaGoï¼‰\n",
    "- æœºå™¨äººå­¦å’Œæ§åˆ¶ç†è®ºï¼ˆè¿åŠ¨è§„åˆ’ã€åŒè¶³æœºå™¨äººè¡Œèµ°ï¼‰\n",
    "- ä¼˜åŒ–ï¼ˆè°·æ­Œåœ°å›¾é€‰æ‹©è·¯çº¿ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `numpy` åº“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ¦‚è§ˆ\n",
    "\n",
    "* è§’è‰²ï¼šç§‘å­¦è®¡ç®—ï¼ˆä½¿ç”¨é˜µåˆ—ï¼‰\n",
    "* ç½‘ç«™ï¼š https://numpy.org/\n",
    "* è¯´æ˜ï¼ˆæ‘˜è‡ª [æ­¤å¤„](https://numpy.org/doc/stable/user/absolute_beginners.html)ï¼‰ï¼š\n",
    "> NumPy (Numerical Python) is an open source Python library thatâ€™s used in almost every field of science and engineering. Itâ€™s the universal standard for working with numerical data in Python, and itâ€™s at the core of the scientific Python and PyData ecosystems. NumPy users include everyone from beginning coders to experienced researchers doing state-of-the-art scientific and industrial research and development. The NumPy API is used extensively in Pandas, SciPy, Matplotlib, scikit-learn, scikit-image and most other data science and scientific Python packages.\n",
    "* æ–‡çŒ®èµ„æ–™ï¼šhttps://numpy.org/devdocs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### åº”ç”¨\n",
    "\n",
    "- ä»¥æ•°ç»„å½¢å¼åˆ›å»ºå‘é‡ï¼ˆä¸€ç»´ï¼‰ã€çŸ©é˜µï¼ˆäºŒç»´ï¼‰å’Œå¼ é‡ï¼ˆ>=ä¸‰ç»´ï¼‰\n",
    "- ä½¿ç”¨å¤§é‡é«˜çº§æ•°å­¦å‡½æ•°å¯¹è¿™äº›æ•°ç»„è¿›è¡Œæ“ä½œ\n",
    "- åœ¨ \"pandas\"ã€\"scipy\"ã€\"matplotlib\"ã€\"scikit-learn \"å’Œå¤§å¤šæ•°å…¶ä»–æ•°æ®ç§‘å­¦å’Œç§‘å­¦ Python è½¯ä»¶åŒ…ä¸­å¹¿æ³›ä½¿ç”¨\n",
    "![](https://res.cloudinary.com/practicaldev/image/fetch/s--oTgfo1EL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0201a.png)\n",
    "\n",
    "å›¾æºï¼šhttps://dev.to/mmithrakumar/scalars-vectors-matrices-and-tensors-with-tensorflow-2-0-1f66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pandas` åº“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ¦‚è§ˆ\n",
    "\n",
    "* è§’è‰²ï¼šæ•°æ®å¤„ç†å’Œåˆ†æ\n",
    "* ç½‘ç«™ï¼š https://pandas.pydata.org/\n",
    "* è¯´æ˜ï¼ˆæ‘˜è‡ª [æ­¤å¤„](https://pandas.pydata.org/)ï¼‰ï¼š\n",
    "> pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n",
    "built on top of the Python programming language.\n",
    "* æ–‡æ¡£ï¼šhttps://pandas.pydata.org/pandas-docs/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### åº”ç”¨\n",
    "\n",
    "æ‘˜è‡ªï¼šhttps://medium.com/dunder-data/how-to-learn-pandas-108905ab4955\n",
    "\n",
    "> `pandas` å¯ä»¥å®Œæˆè®¸å¤šä»»åŠ¡ï¼ŒåŒ…æ‹¬\n",
    "\n",
    ">\n",
    "\n",
    "> è¯»å–/å†™å…¥å¤šç§ä¸åŒçš„æ•°æ®æ ¼å¼\n",
    "\n",
    "> é€‰æ‹©æ•°æ®å­é›†\n",
    "\n",
    "> è·¨è¡Œå’Œè·¨åˆ—è®¡ç®—\n",
    "\n",
    "> æŸ¥æ‰¾å’Œå¡«è¡¥ç¼ºå¤±æ•°æ®\n",
    "\n",
    "> å¯¹æ•°æ®ä¸­çš„ç‹¬ç«‹ç»„è¿›è¡Œæ“ä½œ\n",
    "\n",
    "> å°†æ•°æ®é‡å¡‘ä¸ºä¸åŒçš„å½¢å¼\n",
    "\n",
    "> é€šè¿‡ matplotlib å’Œ seaborn å®ç°å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame`å’Œ`Series`ã€‚\n",
    "\n",
    "pandas \"åº“æœ‰ä¸¤ä¸ªä¸»è¦çš„æ•°æ®å®¹å™¨ï¼š\"DataFrame\"ï¼ˆäºŒç»´ï¼‰å’Œ \"Series\"ï¼ˆä¸€ç»´ï¼‰ã€‚\n",
    "\n",
    "- `DataFrame` [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):\n",
    "  > Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). Arithmetic operations align on both row and column labels. Can be thought of as a dict-like container for Series objects. The primary pandas data structure\n",
    "- `Series` [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html):\n",
    "  > One-dimensional ndarray with axis labels (including time series).\n",
    "\n",
    "\n",
    "æ•°æ®å¸§ \"æ¯” \"ç³»åˆ— \"ä½¿ç”¨å¾—æ›´å¤šï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹å®ƒçš„ç»„æˆéƒ¨åˆ†ã€‚\n",
    "\n",
    "![DataFrame anatomy](https://raw.githubusercontent.com/volkamerlab/ai_in_medicine/master/images/dataframe_anatomy.png)\n",
    "\n",
    "å›¾æºï¼šhttps://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-6fcd0170be9c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.å®ç”¨æ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>æˆ‘ä»¬çš„ç›®æ ‡ï¼š</b>æˆ‘ä»¬å°†ä»‹ç»ç†ŠçŒ«çš„æ‰€æœ‰åŠŸèƒ½ï¼Œè¿™äº›åŠŸèƒ½æ˜¯æˆ‘ä»¬æŒ‰å¹´é¾„ç»„å’Œåœ°åŒºå¯è§†åŒ–æŸæ— COVID-19 æœ€æ–°ç—…ä¾‹æ•°æ‰€å¿…éœ€çš„ã€‚åœ¨äº†è§£äº†å¦‚ä½•å®ç°å¯è§†åŒ–ä¹‹åï¼Œæ‚¨å°†è·å¾—å¾·å›½ç–«è‹—æ¥ç§è¿›å±•çš„æœ€æ–°æ•°æ®ï¼Œå¹¶äº²è‡ªç»˜åˆ¶é¦–æ¬¡/ç¬¬äºŒæ¬¡ç–«è‹—æ¥ç§çš„æ—¶é—´è¿›ç¨‹å›¾ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.æ•°æ®é›†\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ç½—ä¼¯ç‰¹-ç§‘èµ«ç ”ç©¶æ‰€ï¼ˆRKIï¼‰æ¯å¤©å‘å¸ƒçš„ COVID-19 ç—…ä¾‹æ•°æ®ï¼Œè¿™äº›æ•°æ®åœ¨ RKI COVID-19 Dashboard(https://corona.rki.de) ä¸Šå¯ä»¥éå¸¸ç›´è§‚åœ°æ˜¾ç¤ºå‡ºæ¥ã€‚åœ¨æœ¬ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨æŸæ—çš„æ•°æ®ã€‚\n",
    "\n",
    "è¯¥æ•°æ®é›†å¯åœ¨æ­¤å¤„å…è´¹è·å–ï¼šæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹ç½‘å€å°†æ•°æ®é›†ç›´æ¥åŠ è½½åˆ°pandasä¸­ï¼š https://opendata.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.ç”¨ `pandas` ä½œä¸º `DataFrame` è¯»å–æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆï¼Œæˆ‘ä»¬å¯¼å…¥åº“ `numpy` å’Œ `pandas`ï¼ˆç¼©å†™ä¸º `np` å’Œ `pd`ï¼Œè¿™æ ·æˆ‘ä»¬å°±èƒ½å†™å‡ºæ›´ç®€çŸ­çš„ä»£ç ï¼‰ã€‚åº“æ˜¯ä¸€ç³»åˆ—åŠŸèƒ½çš„é›†åˆï¼Œèƒ½è®©ä½ åœ¨æ— éœ€ä»å¤´å¼€å§‹ç¼–å†™å…¨éƒ¨ä»£ç çš„æƒ…å†µä¸‹æ‰§è¡Œè®¸å¤šå¸¸è§ä»»åŠ¡ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œ\"pandas \"åº“æä¾›äº† \"read_csv() \"å‡½æ•°ï¼Œç”¨äºå°†é€—å·åˆ†éš”å€¼ï¼ˆcsvï¼‰æ–‡ä»¶è¯»å…¥æ‰€è°“çš„ \"æ•°æ®å¸§\"ã€‚\n",
    "\n",
    "**æç¤º**ï¼šæ‚¨å¯ä»¥åœ¨æœ¬ Jupyter ç¬”è®°æœ¬ä¸­æŸ¥çœ‹æŸä¸ªåº“çš„å¯ç”¨åŠŸèƒ½ï¼Œæ–¹æ³•æ˜¯åœ¨åº“ååé¢å†™ä¸€ä¸ªç‚¹ï¼Œç„¶åæŒ‰ tab é”®ã€‚æ‰€æœ‰å¯ç”¨åŠŸèƒ½éƒ½å°†å¼¹å‡ºï¼Œä¾›ä½ æ¢ç´¢ã€‚ç”±äºé€‰é¡¹å¾ˆå¤šï¼Œä½ å¯ä»¥åœ¨å¼¹å‡ºçª—å£æ—¶å†™ä¸Š \"é˜…è¯» \"ç­‰å­—æ ·æ¥ç¼©å°èŒƒå›´ã€‚\n",
    "\n",
    "**æ³¨æ„***ï¼šå¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ Google Colabï¼Œåˆ™å¿…é¡»é¦–å…ˆåœ¨ \"å·¥å…·\">\"è®¾ç½®\">\"ç¼–è¾‘å™¨ \"ä¸­ç¦ç”¨ \"è‡ªåŠ¨è§¦å‘ä»£ç è¡¥å…¨\"ï¼Œæ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚\n",
    "\n",
    "æ‚¨å¯ä»¥é€šè¿‡ `pandas` é˜…è¯»æ‰€æœ‰å¯èƒ½çš„æ–‡ä»¶æ ¼å¼ï¼š"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.read  # å…‰æ ‡ä½äº \"pd.read \"ä¹‹åæ—¶ï¼ŒæŒ‰ä¸‹åˆ¶è¡¨ç¬¦é”®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæˆ‘ä»¬æ‰§è¡Œï¼ˆç”¨ `Enter`ï¼‰è¿™ä¸ªå•å…ƒæ ¼ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ª `AttributeError` å› ä¸ºæ¨¡å— `pandas` ä¸çŸ¥é“ `read()`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ `?` è·å–å‡½æ•°çš„ docstringï¼Œå³å…³äºè¯¥å‡½æ•°çš„ä½œç”¨å’Œå¯ä»¥ä¼ é€’çš„å‚æ•°ç±»å‹çš„è¯´æ˜ï¼"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `read_csv()` å‡½æ•°ï¼ˆ[å‚è§æ–‡æ¡£](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)ï¼‰å°† csv æ–‡ä»¶å†…å®¹ä½œä¸º `DataFrame` åŠ è½½åˆ°å˜é‡ `data_raw` ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    719\u001b[0m     path_or_buf,\n\u001b[1;32m    720\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    721\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    722\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    723\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    724\u001b[0m )\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# `read_csv`å¯ä»¥è¯»å–è®¡ç®—æœºä¸­çš„è·¯å¾„ï¼Œä¹Ÿå¯ä»¥è¯»å–äº’è”ç½‘ URLï¼\n",
    "# è¯»å–è¿œç¨‹ csv æ–‡ä»¶åªéœ€å‡ ç§’é’Ÿ\n",
    "data_raw = pd.read_csv(\"https://opendata.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬æ¥çœ‹çœ‹ `data_raw` ä¸­çš„ `DataFrame` ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.æŸ¥çœ‹æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame` å¤´/å°¾\n",
    "\n",
    "è®©æˆ‘ä»¬ä½¿ç”¨ `head()` å‡½æ•°ï¼ˆ[å‚è§æ–‡æ¡£](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html)ï¼‰çœ‹çœ‹è¡¨æ ¼çš„å‰å‡ è¡Œã€‚\n",
    "\n",
    "**æ³¨æ„**ï¼šä¸ºäº†é¿å…åœ¨æœ¬ Jupyter ç¬”è®°æœ¬ä¸­æ‰“å°å¤§å‹è¡¨æ ¼ï¼Œæˆ‘ä»¬ä¼šç»å¸¸ä½¿ç”¨è¯¥å‘½ä»¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.head()  # Shows by default the first 5 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬ä½¿ç”¨ `tail()` å‡½æ•°ï¼ˆ[å‚è§æ–‡æ¡£](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html)ï¼‰çœ‹çœ‹è¡¨æ ¼çš„æœ€åå‡ è¡Œã€‚è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥å‘ `head()` å’Œ `tail()` å‡½æ•°ä¼ é€’ä¸€ä¸ªæ•°å­—ï¼Œä»¥æŒ‡å®šè¦æŸ¥çœ‹çš„ç¬¬ä¸€è¡Œ/æœ€åä¸€è¡Œçš„æ•°é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame` ç»´åº¦\n",
    "\n",
    "è®©æˆ‘ä»¬ä½¿ç”¨ `shape` ä»¥ `ï¼ˆè¡Œæ•°ï¼Œåˆ—æ•°ï¼‰` çš„å½¢å¼æ˜¾ç¤ºè¡¨æ ¼çš„åˆ—æ•°å’Œè¡Œæ•°ï¼ˆ= ç»´åº¦/å½¢çŠ¶ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame` åˆ—å\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `columns`è·å–æ‰€æœ‰åˆ—åã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list here the meaning of a few criteria (see full list on [RKI COVID-19 data download website](https://www.arcgis.com/home/item.html?id=dd4580c810204019a7b8eb3e0b329dd6)):\n",
    "\n",
    "- `Bundesland`: State name\n",
    "- `Landkreis`: District name\n",
    "- `Altersgruppe`: Age group (6 groups: `0-4`, `5-14`, `15-34`, `35-59`, `60-79`, `80+` and `unbekannt`=unknown)\n",
    "- `Geschlecht`: Gender (`M`=male, `W`=female and `unbekannt`=unknown)\n",
    "- `AnzahlFall`: Number of cases in group\n",
    "- `AnzahlTodesfall`: Number of deaths in group\n",
    "- `AnzahlGenesen`: Number of recoveries cases in group\n",
    "- `Meldedatum`: Date when case was reported to the Gesundheitsamt (you will use this in the next lesson on data visualization with `matplotlib`)\n",
    "- `Datenstand`: Date when data was updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥æŠŠ \"DataFrame \"çœ‹ä½œæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ˆæ¯ä¸ªåˆ—è¡¨å¯ä»¥åŒ…å«ä¸åŒçš„æ•°æ®ç±»å‹ï¼‰ï¼Œå®ƒä»¥è¡¨æ ¼çš„å½¢å¼æ˜¾ç¤ºï¼Œå¹¶å¸¦æœ‰åˆ—åå’Œç´¢å¼•åç­‰å…ƒæ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [['Helen', 20, 'female'], ['Paul', 25, 'male'], ['Kim', 35, 'female']]\n",
    "list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list_of_lists, columns=['name', 'age', 'gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_ï¼šç»ƒä¹ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1__: è·å– (a) `data_raw` ä¸­çš„å‰ 4 è¡Œå’Œ (b) æœ€å 5 è¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2__: è·å– (a) `data_raw` ä¸­çš„åˆ—æ•°å’Œ (b) ç¬¬ä¸‰åˆ—åç§°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 3__: å»ºç«‹ä¸€ä¸ªåŒ…å« 4 ä¸ªå›½å®¶æ•°æ®çš„ `DataFrame` ï¼š\n",
    "\n",
    "- å›½å®¶åç§°\n",
    "- æ‚¨æœ€å–œæ¬¢çš„å›½å®¶\n",
    "- æ‚¨å»è¿‡é‚£é‡Œå—ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â¤ï¸æ¥ä¸‹æ¥ï¼Œæˆ‘ä¸æƒ³ç”¨ä¸­æ–‡äº†ï¼Œæˆ‘æœ¬æ¥æƒ³é”»ç‚¼è‡ªå·±çš„è‹±è¯­çš„ï¼ŒğŸ˜­ï¼Œä½ ä»¬å°±çœ‹è‹±è¯­å§â¤ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Select columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By column name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select some interesting columns! The `DataFrame` is quite large and we are only interested in a subset of the offered criteria. With `pandas`, it is very easy to slice the columns that you want by the following syntax:\n",
    "\n",
    "```python\n",
    "data_raw[list_of_interesting_columns]\n",
    "```\n",
    "\n",
    "The list of column names of interest could look like this:\n",
    "```python\n",
    "list_of_interesting_columns = ['Bundesland', 'Landkreis']\n",
    "```\n",
    "\n",
    "Taking both steps together it looks like this (note the two sets of `[]`, the inner `[]` is part of the list, the outer `[]` is the syntax for `DataFrame` slicing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw[['Bundesland', 'Landkreis']].head()  # Note the use of .head() to show only the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in the following that it is possible to write a command over multiple lines to make is easier to read.\n",
    "\n",
    "Let's write this operation's output into the variable `data`; we will use this variable from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw[\n",
    "    [\n",
    "        'Bundesland', \n",
    "        'Landkreis', \n",
    "        'Altersgruppe', \n",
    "        'Geschlecht', \n",
    "        'AnzahlFall', \n",
    "        'AnzahlTodesfall', \n",
    "        'AnzahlGenesen', \n",
    "        'Datenstand'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have noticed that there is no cell output as before. This happens when the output is saved in a variable (here `data`). Let's inspect the content of `data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By column AND index names/indices using `loc/iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Recap__\n",
    "\n",
    "So far we sliced columns using column names like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Bundesland', 'Landkreis']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __`loc`__\n",
    "\n",
    "The above code is a shorter form for using `loc`:\n",
    "```python\n",
    "dataframe.loc[list_of_row_names, list_of_column_names]\n",
    "```\n",
    "`index_names` or `column_names` can be set to `:` if we want to select the full row or column, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, ['Bundesland', 'Landkreis']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __`iloc`__\n",
    "\n",
    "Or, instead of row and column names, we can use their indices (like you learnt on day 1 where you selected elements from a list). \n",
    "\n",
    "```python\n",
    "dataframe.iloc[list_of_row_indices, list_of_column_indices].head()\n",
    "```\n",
    "\n",
    "Remember, in Python indices are 0-indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out index of columns of interest\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:, [2, 3]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: You will use `loc/iloc` in the notebooks to come in the next lessons, but for this lesson here, we will use column selection by column names as discussed first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Bundesland', 'Landkreis']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4__: Select the columns listing the number of cases, deaths and recoveries using their __column names__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 5__: Do the same as in Exercise 4 but this time use __`loc`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 6__: Do the same as in Exercise 4 and 5 but this time use __`iloc`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Get unique entries in a column\n",
    "\n",
    "Now, we'd like to check what kind of entries we can find in a column. \n",
    "\n",
    "First, we select a column, similar to how we learned it in *Chapter 5.4*. Since we select this time only **one** column, we do not pass the column name as a list but as a simple string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Bundesland'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a `Series` (instead of a `DataFrame`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['Bundesland'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply the `unique()` function ([see docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html)) and check the states in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Bundesland'].unique()  # Note: Here we pass the single column as string not as list (as shown in Chapter 5.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 16 states, let's check with Python's built-in function `len` ([see docs](https://docs.python.org/3/library/functions.html#len)) that returns the length of e.g. list-like objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Bundesland'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 7__: Select the column on age groups (`'Altersgruppe'`) - which age groups are monitored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 8__: Select the column on districts (`'Landkreis'`) - how many districts are monitored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6. Select rows (by conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often, you not only have more criteria (columns) in your dataset than you are actually interested in but also more data points (rows) than you need. Let's say for instance, that we are mainly interested in data points regarding Berlin. Since we have a dataset for Germany, we will need to do some (row) filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select only the state column (`Bundesland`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Bundesland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `Series` it is very easy to check for each row if it fullfils a given condition. As an example, let's ask for \"ThÃ¼ringen\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Bundesland'] == 'ThÃ¼ringen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see, that this operation returns a `Series` of the same length and index as our initial `Series` containing boolean values (`True` or `False`).\n",
    "\n",
    "How can we use this boolean Series know to subset `data` for data points concerning Berlin (i.e. filter `data` for rows concerning Berlin)? We use the following syntax:\n",
    "\n",
    "```python\n",
    "data[condition]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition\n",
    "state_is_berlin = data['Bundesland'] == 'Berlin'\n",
    "\n",
    "# Subset dataset by condition\n",
    "data[state_is_berlin]  # equals\n",
    "data[data['Bundesland'] == 'Berlin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 9__: Select only data points for Berlin Mitte (one condition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 10__: Select only data points for Berlin and patients between 35 and 59 years old (two conditions).\n",
    "\n",
    "```python\n",
    "# Use one condition\n",
    "data[condition]\n",
    "\n",
    "# Use multiple conditions\n",
    "data[condition1 & condition2]  # Fullfill condition 1 AND 2\n",
    "data[condition1 & not condition2]  # Fullfill condition 1 AND not 2\n",
    "data[condition1 | condition2]  # Fullfill condition 1 OR 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7. Group data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, we will continue to work only with data for Berlin, so we will save the subset to the new variable `data_berlin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_berlin = data[data['Bundesland'] == 'Berlin']\n",
    "data_berlin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html:\n",
    "\n",
    "> By `groupby()` we are referring to a process involving one or more of the following steps:\n",
    "> * **Splitting** the data into groups based on some criteria.\n",
    "> * **Applying** a function to each group independently.\n",
    "> * **Combining** the results into a data structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Get group sum with `sum()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting**: Split data into groups based on a criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_berlin.groupby('Altersgruppe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_berlin.groupby('Altersgruppe'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at one of the groups (= subset of the full DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_berlin.groupby('Altersgruppe').get_group(\"A00-A04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying and combining**: Apply function to each group, e.g. get the sum of numerical values in each group using `sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_berlin.groupby('Altersgruppe').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `pandas` it is very easy to quickly plot data using the `plot()` function ([see docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html)) - with the parameter `kind` you can specify what plot type you want to plot (in our case we want a barplot). Note that the index labels will serve as x-axis labels.\n",
    "\n",
    "Select `AnzahlFall` for the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_berlin.groupby('Altersgruppe').sum()['AnzahlFall'].plot(\n",
    "    kind='bar', \n",
    "    title=f'Number of all COVID19 cases in Berlin since the beginning of the pandemic ({data[\"Datenstand\"].unique()[0]})'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this plot with the [RKI Dashboard](https://corona.rki.de/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Your turn_: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 11__: Since the `groupby` functionality is very powerful but also at first difficult to wraps our head around, go through the first two examples above again in your group and discuss questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 12__: Get number of total COVID-19 cases by Berlin's districts and compare your findings to the [official COVID-19 table for Berlin > Bezirke > Ãœbersicht](https://www.berlin.de/corona/lagebericht/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 13__: Plot the number of total COVID-19 cases in Berlin grouped by Berlin's districts (barplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discussion\n",
    "\n",
    "In this notebook, we saw how quickly possible it is to read in a csv file as `DataFrame` (*Chapter 5.2*) and to start working with it. \n",
    "- We got a first impression on our COVID-19 Berlin dataset. We looked at the number of data points (`DataFrame` rows) and criteria (`DataFrame` columns) as well as some example data points, see *Chapter 5.3*.\n",
    "- We selected interesting columns and checked what kind of column entries we can except, see *Chapter 5.4 and 5.5*. \n",
    "- We grouped data by certain criteria (columns), and applied operations on these groups, e.g. we calculated the sum within each group). We also did some first steps towards plotting with `pandas`, see *Chapter 5.6*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final exercise\n",
    "\n",
    "As promised at the beginning, you will get your own dataset now :)\n",
    "\n",
    "Last year during the course, we could only work with COVID-19 cases data but luckily, this year, we have something positive to look at as well - the vaccination progress in Germany! You can find that data online again at the [RKI website](https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Daten/Impfquoten-Tab.html) (under the \"Daten\" section). \n",
    "\n",
    "The provided Excel file is a bit difficult to handle, thus many GitHub repos have been set up to process the dataset into formats that are easier to work with, e.g. https://github.com/ard-data/2020-rki-impf-archive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let's load the cumulative vaccination progress for Germany. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccination_cumulative = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/ard-data/2020-rki-impf-archive/master/data/9_csv_v3/region_DE.csv\"\n",
    ")\n",
    "vaccination_cumulative.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Let the `date` column know that it represents dates (change data structure from `object` to `datetime`). This will help us later during plotting because `pandas` will not try to label each day in the plot but maybe rather every month (depending on the range of dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccination_cumulative[\"date\"] = pd.to_datetime(vaccination_cumulative[\"date\"])\n",
    "vaccination_cumulative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccination_cumulative.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Set the date as the `DataFrame` index. Use `your_dataframe.set_index(column_name)` for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Select only the columns containing the cumulative number of people who are fully vaccinated or vaccinated once/twice (`personen_voll_kumulativ`, `personen_erst_kumulativ`, and `personen_zweit_kumulativ`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Plot the cumulative time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compare your results to the data on the BMG website: https://impfdashboard.de/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solutions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Words of encouragement :)__ \n",
    "\n",
    "Before you take a look at the solutions, try to solve the exercises yourself. \n",
    "\n",
    "All the information needed lives in _5. Practical_ - if you are stuck, first take a look at the material there. Talk to your fellow students. If you have a solution, then go ahead and take a look here.\n",
    "\n",
    "Also note that the solutions given here show only one possibility - most of the times there are multiple options to achieve the same end result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 1</summary>\n",
    "    \n",
    "```python\n",
    "data.head(4)\n",
    "data.tail()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 2</summary>\n",
    "    \n",
    "```python\n",
    "len(data.columns)\n",
    "data.columns[2]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 3</summary>\n",
    "    \n",
    "```python\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        [\"France\", \"GewÃ¼rztraminer\", True], \n",
    "        [\"Australia\", \"beautiful nature\", True], \n",
    "        [\"Israel\", \"hummus\", True], \n",
    "        [\"Iceland\", \"language\", False]\n",
    "    ], \n",
    "    columns=[\"country\", \"awesome because of\", \"been there\"]\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 4</summary>\n",
    "    \n",
    "```python\n",
    "data[[\"AnzahlFall\", \"AnzahlTodesfall\", \"AnzahlGenesen\"]]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 5</summary>\n",
    "    \n",
    "```python\n",
    "data.loc[:, [\"AnzahlFall\", \"AnzahlTodesfall\", \"AnzahlGenesen\"]]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 6</summary>\n",
    "    \n",
    "```python\n",
    "data.iloc[:, [4, 5, 6]]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 7</summary>\n",
    "    \n",
    "```python\n",
    "data[\"Altersgruppe\"].unique()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 8</summary>\n",
    "    \n",
    "```python\n",
    "len(data[\"Landkreis\"].unique())\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 9</summary>\n",
    "    \n",
    "```python\n",
    "data[data[\"Landkreis\"] == \"SK Berlin Mitte\"]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 10</summary>\n",
    "    \n",
    "```python\n",
    "data[\n",
    "    (data[\"Bundesland\"] == \"Berlin\") & \n",
    "    (data[\"Altersgruppe\"] == \"A35-A59\")\n",
    "]\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 11</summary>\n",
    "    \n",
    "Go through _Chapter 5.6._ one more time.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 12</summary>\n",
    "    \n",
    "```python\n",
    "data_berlin.groupby('Landkreis')['AnzahlFall'].sum()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution 13</summary>\n",
    "    \n",
    "```python\n",
    "data_berlin.groupby('Landkreis')['AnzahlFall'].sum().plot(\n",
    "    kind='bar', title=f'Number of COVID-19 cases in Berlin'\n",
    ")\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> > Solution to final exercise</summary>\n",
    "    \n",
    "```python\n",
    "vaccination_cumulative = vaccination_cumulative.set_index(\"date\")\n",
    "vaccination_cumulative = vaccination_cumulative[[\"personen_erst_kumulativ\", \"personen_voll_kumulativ\", \"personen_zweit_kumulativ\"]]\n",
    "vaccination_cumulative.plot()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
