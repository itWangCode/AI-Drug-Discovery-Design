{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Generate new molecules for glioblastoma\n",
    "# 生成治疗 glioblastoma 的新分子"
   ],
   "id": "3a0b6da3b3703d2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 代码过程的解释\n",
    "**检查可用设备**：使用 GPU（如果可用）或 CPU。\n",
    "\n",
    "**导入必要的库**：包括 PyTorch、NumPy、Pandas 等。\n",
    "\n",
    "**设置随机种子**：使用 `seed_all()` 函数设置随机种子，以确保结果的可重复性\n",
    "\n",
    "**加载数据集**：使用 Pandas 加载 CSV 文件，并移除缺失值。\n",
    "\n",
    "**提取 SMILES 和标签**：从数据集中提取需要的列。\n",
    "\n",
    "**划分数据集**：使用 `train_test_split` 将数据集划分为训练、验证和测试集。\n",
    "\n",
    "**构建词汇表**：从训练数据中提取所有可能的字符，构建词汇表和映射关系。\n",
    "\n",
    "**定义必要的函数**：包括字符和索引之间的转换函数，以及字符串和张量之间的转换函数。\n",
    "\n",
    "**定义 VAE 模型**：包含编码器和解码器，以及采样函数。\n",
    "\n",
    "**定义训练参数**：设置训练所需的超参数，如学习率、批次大小等。\n",
    "\n",
    "**定义辅助类和函数**：包括 KL 权重退火器、学习率调度器、循环缓冲区、日志记录器等。\n",
    "\n",
    "**定义训练函数**：包括 `_train_epoch` 和 `_train` 函数，以及 `fit` 函数来开始训练。\n",
    "\n",
    "**定义数据加载器相关函数**：包括 `get_dataloader`、`get_collate_fn` 等。\n",
    "\n",
    "**定义采样函数**：用于从训练好的模型中生成新的 SMILES 字符串。\n",
    "\n",
    "**初始化模型**：创建 VAE 模型的实例并将其移动到指定设备上。\n",
    "\n",
    "**训练模型**：使用 `fit` 函数训练模型。\n",
    "\n",
    "**保存模型**：将训练好的模型参数保存到指定路径。\n",
    "\n",
    "**生成样本**：从训练好的模型中生成新的分子，并将结果保存到 CSV 文件中。\n",
    "\n",
    "**保存损失值**：将训练过程中记录的损失值保存到 CSV 文件中，以便后续分析。"
   ],
   "id": "28eebcb0f161b024"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **注意事项**\n",
    "\n",
    "- **路径设置**：请确保您的数据集文件 `egfr_data_ubstructures_matches.csv` 位于代码运行的目录中，或者提供正确的文件路径。\n",
    "- **目录创建**：在保存模型和生成的样本时，代码中使用了 `os.makedirs()` 创建目录。如果目录已存在，不会报错。\n",
    "- **模型保存和加载**：在保存和加载模型时，请确保文件路径正确。如果您想在训练后加载模型，请取消相应的注释。\n",
    "- **GPU 使用**：如果您的计算机上有 GPU，并且已正确安装了 CUDA，代码将自动使用 GPU 进行训练。\n",
    "- **运行时间**：由于训练迭代次数较多（`n_epoch = 100`），训练过程可能需要较长时间。您可以根据需要调整训练轮数。\n",
    "\n",
    "### "
   ],
   "id": "56c69520356ba44a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:50.354596Z",
     "start_time": "2024-10-18T03:01:50.350469Z"
    }
   },
   "source": [
    "# Importing necessary libraries\n",
    "# 检测是否是GPU可用，⚠️，本次教程，必须必须必须❤️需要采用4060 以上的显卡，否则会报错，你电脑报废了！！！\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:50.685334Z",
     "start_time": "2024-10-18T03:01:50.679960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# 获取当前工作目录\n",
    "HERE = Path(os.getcwd())\n",
    "DATA = HERE / 'data'\n",
    "if not DATA.exists():\n",
    "    DATA.mkdir(parents=True, exist_ok=True)\n",
    "print(DATA)"
   ],
   "id": "dd69c27d2db4b3b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wangyang/Desktop/AI-drug-design/list/05_workshop/02_Generate_new_molecules_glioblastoma/data\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:51.007073Z",
     "start_time": "2024-10-18T03:01:51.001636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import deepchem as dc\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from collections import UserList, defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rdkit import RDLogger                                                                                                                                                               \n"
   ],
   "id": "e237d0a89b3174c5",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:51.440767Z",
     "start_time": "2024-10-18T03:01:51.438021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 禁用 RDKit 日志\n",
    "RDLogger.DisableLog('rdApp.*')"
   ],
   "id": "fe8ec22bbc5d22e6",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:51.782028Z",
     "start_time": "2024-10-18T03:01:51.776655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置随机种子，以确保可重复性\n",
    "def seed_all(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "seed_all()"
   ],
   "id": "5f1139a4c32f92c9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:52.064266Z",
     "start_time": "2024-10-18T03:01:52.047880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载数据集\n",
    "df = pd.read_csv(DATA / 'egfr_data_ubstructures_matches.csv')\n",
    "df = df[df['smiles'].notnull()]  # 移除缺失值"
   ],
   "id": "d3aff822f1acc990",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:52.455019Z",
     "start_time": "2024-10-18T03:01:52.444441Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "cd90d5a4203222af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  molecule_chembl_id   IC50 units                               smiles  \\\n",
       "0        CHEMBL35820  0.006    nM  CCOc1cc2ncnc(Nc3cccc(Br)c3)c2cc1OCC   \n",
       "1        CHEMBL53711  0.006    nM   CN(C)c1cc2c(Nc3cccc(Br)c3)ncnc2cn1   \n",
       "2        CHEMBL53753  0.008    nM      CNc1cc2c(Nc3cccc(Br)c3)ncnc2cn1   \n",
       "3        CHEMBL66031  0.008    nM  Brc1cccc(Nc2ncnc3cc4[nH]cnc4cc23)c1   \n",
       "4       CHEMBL176582  0.010    nM  Cn1cnc2cc3ncnc(Nc4cccc(Br)c4)c3cc21   \n",
       "\n",
       "       pIC50  ro5_fulfilled                                             ROMol  \n",
       "0  11.221849           True  <rdkit.Chem.rdchem.Mol object at 0x7fbdb826e190>  \n",
       "1  11.221849           True  <rdkit.Chem.rdchem.Mol object at 0x7fbdb826e200>  \n",
       "2  11.096910           True  <rdkit.Chem.rdchem.Mol object at 0x7fbdb826e270>  \n",
       "3  11.096910           True  <rdkit.Chem.rdchem.Mol object at 0x7fbdb826e2e0>  \n",
       "4  11.000000           True  <rdkit.Chem.rdchem.Mol object at 0x7fbdb826e350>  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_chembl_id</th>\n",
       "      <th>IC50</th>\n",
       "      <th>units</th>\n",
       "      <th>smiles</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>ro5_fulfilled</th>\n",
       "      <th>ROMol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL35820</td>\n",
       "      <td>0.006</td>\n",
       "      <td>nM</td>\n",
       "      <td>CCOc1cc2ncnc(Nc3cccc(Br)c3)c2cc1OCC</td>\n",
       "      <td>11.221849</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7fbdb826e190&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL53711</td>\n",
       "      <td>0.006</td>\n",
       "      <td>nM</td>\n",
       "      <td>CN(C)c1cc2c(Nc3cccc(Br)c3)ncnc2cn1</td>\n",
       "      <td>11.221849</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7fbdb826e200&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL53753</td>\n",
       "      <td>0.008</td>\n",
       "      <td>nM</td>\n",
       "      <td>CNc1cc2c(Nc3cccc(Br)c3)ncnc2cn1</td>\n",
       "      <td>11.096910</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7fbdb826e270&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL66031</td>\n",
       "      <td>0.008</td>\n",
       "      <td>nM</td>\n",
       "      <td>Brc1cccc(Nc2ncnc3cc4[nH]cnc4cc23)c1</td>\n",
       "      <td>11.096910</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7fbdb826e2e0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL176582</td>\n",
       "      <td>0.010</td>\n",
       "      <td>nM</td>\n",
       "      <td>Cn1cnc2cc3ncnc(Nc4cccc(Br)c4)c3cc21</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7fbdb826e350&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:52.827549Z",
     "start_time": "2024-10-18T03:01:52.824118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 提取 SMILES 和标签\n",
    "smiles_list = df['smiles'].tolist()\n",
    "labels = df['pIC50'].tolist()"
   ],
   "id": "f5e6d050d5f913d6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:53.163502Z",
     "start_time": "2024-10-18T03:01:53.156552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 划分数据集（80% 训练，10% 验证，10% 测试）\n",
    "train_smiles, temp_smiles, train_labels, temp_labels = train_test_split(\n",
    "    smiles_list, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "valid_smiles, test_smiles, valid_labels, test_labels = train_test_split(\n",
    "    temp_smiles, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f'Compound train/valid/test split: {len(train_smiles)}/{len(valid_smiles)}/{len(test_smiles)}')\n"
   ],
   "id": "72662f5b8f9c1c21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound train/valid/test split: 1955/244/245\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:53.445949Z",
     "start_time": "2024-10-18T03:01:53.442604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 更新训练数据\n",
    "train_data = train_smiles\n",
    "train_label = train_labels"
   ],
   "id": "64a6b0454dbcfde7",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:01:53.756132Z",
     "start_time": "2024-10-18T03:01:53.750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 构建词汇表\n",
    "chars = set()\n",
    "for string in train_data:\n",
    "    chars.update(string)\n",
    "all_sys = sorted(list(chars)) + ['<bos>', '<eos>', '<pad>', '<unk>']\n",
    "vocab = all_sys\n",
    "c2i = {c: i for i, c in enumerate(all_sys)}  # 字符到索引的映射\n",
    "i2c = {i: c for i, c in enumerate(all_sys)}  # 索引到字符的映射"
   ],
   "id": "c0d3e523a63a7d90",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:03:49.781399Z",
     "start_time": "2024-10-18T03:03:49.778049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建独热编码向量\n",
    "vector = torch.eye(len(c2i))"
   ],
   "id": "3580e2150e9852d5",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:04:02.846806Z",
     "start_time": "2024-10-18T03:04:02.839026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义必要的函数\n",
    "def char2id(char):\n",
    "    \"\"\"将字符转换为索引\"\"\"\n",
    "    return c2i.get(char, c2i['<unk>'])\n",
    "\n",
    "def id2char(id):\n",
    "    \"\"\"将索引转换为字符\"\"\"\n",
    "    return i2c.get(id, '<unk>')\n",
    "\n",
    "def string2ids(string, add_bos=False, add_eos=False):\n",
    "    \"\"\"将字符串转换为索引列表\"\"\"\n",
    "    ids = [char2id(c) for c in string]\n",
    "    if add_bos:\n",
    "        ids = [c2i['<bos>']] + ids\n",
    "    if add_eos:\n",
    "        ids = ids + [c2i['<eos>']]\n",
    "    return ids\n",
    "\n",
    "def ids2string(ids, rem_bos=True, rem_eos=True):\n",
    "    \"\"\"将索引列表转换为字符串\"\"\"\n",
    "    if rem_bos and ids and ids[0] == c2i['<bos>']:\n",
    "        ids = ids[1:]\n",
    "    if rem_eos and ids and ids[-1] == c2i['<eos>']:\n",
    "        ids = ids[:-1]\n",
    "    return ''.join([id2char(id) for id in ids])\n",
    "\n",
    "def string2tensor(string, device='cpu'):\n",
    "    \"\"\"将字符串转换为张量\"\"\"\n",
    "    ids = string2ids(string, add_bos=True, add_eos=True)\n",
    "    tensor = torch.tensor(ids, dtype=torch.long, device=device)\n",
    "    return tensor\n",
    "\n",
    "def tensor2string(tensor):\n",
    "    \"\"\"将张量转换为字符串\"\"\"\n",
    "    ids = tensor.tolist()\n",
    "    return ids2string(ids)"
   ],
   "id": "716ed120800ed208",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:04:07.969682Z",
     "start_time": "2024-10-18T03:04:07.925595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将训练数据转换为张量\n",
    "train_tensors = [string2tensor(string, device=device) for string in train_data]\n"
   ],
   "id": "fd21d72addcacf78",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:04:19.107640Z",
     "start_time": "2024-10-18T03:04:19.086377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义 VAE 模型\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, vocab, vector):\n",
    "        super(VAE, self).__init__()\n",
    "        self.vocabulary = vocab\n",
    "        self.vector = vector\n",
    "        n_vocab, d_emb = len(vocab), vector.size(1)\n",
    "\n",
    "        # 嵌入层\n",
    "        self.x_emb = nn.Embedding(n_vocab, d_emb, padding_idx=c2i['<pad>'])\n",
    "        self.x_emb.weight.data.copy_(vector)\n",
    "\n",
    "        # 编码器参数\n",
    "        self.q_bidir = True\n",
    "        self.q_d_h = 256\n",
    "        self.q_n_layers = 1\n",
    "        self.q_dropout = 0.5\n",
    "\n",
    "        # 解码器参数\n",
    "        self.d_n_layers = 3\n",
    "        self.d_dropout = 0.0\n",
    "        self.d_z = 128\n",
    "        self.d_d_h = 512\n",
    "\n",
    "        # 编码器\n",
    "        self.encoder_rnn = nn.GRU(\n",
    "            d_emb,\n",
    "            self.q_d_h,\n",
    "            num_layers=self.q_n_layers,\n",
    "            batch_first=True,\n",
    "            dropout=self.q_dropout if self.q_n_layers > 1 else 0,\n",
    "            bidirectional=self.q_bidir\n",
    "        )\n",
    "        q_d_last = self.q_d_h * (2 if self.q_bidir else 1)\n",
    "        self.q_mu = nn.Linear(q_d_last, self.d_z)\n",
    "        self.q_logvar = nn.Linear(q_d_last, self.d_z)\n",
    "\n",
    "        # 解码器\n",
    "        self.decoder_rnn = nn.GRU(\n",
    "            d_emb + self.d_z,\n",
    "            self.d_d_h,\n",
    "            num_layers=self.d_n_layers,\n",
    "            batch_first=True,\n",
    "            dropout=self.d_dropout if self.d_n_layers > 1 else 0\n",
    "        )\n",
    "        self.decoder_latent = nn.Linear(self.d_z, self.d_d_h)\n",
    "        self.decoder_fullyc = nn.Linear(self.d_d_h, n_vocab)\n",
    "\n",
    "    def device(self):\n",
    "        \"\"\"获取模型所在的设备\"\"\"\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        z, kl_loss = self.forward_encoder(x)\n",
    "        recon_loss = self.forward_decoder(x, z)\n",
    "        return kl_loss, recon_loss\n",
    "\n",
    "    def forward_encoder(self, x):\n",
    "        \"\"\"编码器前向传播\"\"\"\n",
    "        x_emb = [self.x_emb(i_x) for i_x in x]\n",
    "        x_packed = nn.utils.rnn.pack_sequence(x_emb, enforce_sorted=False)\n",
    "        _, h = self.encoder_rnn(x_packed)\n",
    "        if self.q_bidir:\n",
    "            h = h.view(self.q_n_layers, 2, -1, self.q_d_h)\n",
    "            h = torch.cat((h[-1, 0], h[-1, 1]), dim=-1)\n",
    "        else:\n",
    "            h = h[-1]\n",
    "        mu = self.q_mu(h)\n",
    "        logvar = self.q_logvar(h)\n",
    "        eps = torch.randn_like(mu)\n",
    "        z = mu + (logvar / 2).exp() * eps\n",
    "        kl_loss = 0.5 * (logvar.exp() + mu ** 2 - 1 - logvar).sum(1).mean()\n",
    "        return z, kl_loss\n",
    "\n",
    "    def forward_decoder(self, x, z):\n",
    "        \"\"\"解码器前向传播\"\"\"\n",
    "        lengths = [len(i_x) for i_x in x]\n",
    "        x_padded = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=c2i['<pad>'])\n",
    "        x_emb = self.x_emb(x_padded)\n",
    "        z_0 = z.unsqueeze(1).repeat(1, x_emb.size(1), 1)\n",
    "        x_input = torch.cat([x_emb, z_0], dim=-1)\n",
    "        x_packed = nn.utils.rnn.pack_padded_sequence(x_input, lengths, batch_first=True, enforce_sorted=False)\n",
    "        h_0 = self.decoder_latent(z)\n",
    "        h_0 = h_0.unsqueeze(0).repeat(self.d_n_layers, 1, 1)\n",
    "        output, _ = self.decoder_rnn(x_packed, h_0)\n",
    "        output_padded, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        y = self.decoder_fullyc(output_padded)\n",
    "        recon_loss = F.cross_entropy(\n",
    "            y[:, :-1].contiguous().view(-1, y.size(-1)),\n",
    "            x_padded[:, 1:].contiguous().view(-1),\n",
    "            ignore_index=c2i['<pad>']\n",
    "        )\n",
    "        return recon_loss\n",
    "\n",
    "    def sample_z_prior(self, n_batch):\n",
    "        \"\"\"从先验分布中采样 z\"\"\"\n",
    "        return torch.randn(n_batch, self.d_z, device=self.device())\n",
    "\n",
    "    def sample(self, n_batch, max_len=100, z=None, temp=1.0):\n",
    "        \"\"\"生成样本\"\"\"\n",
    "        with torch.no_grad():\n",
    "            if z is None:\n",
    "                z = self.sample_z_prior(n_batch)\n",
    "            z = z.to(self.device())\n",
    "            z_0 = z.unsqueeze(1)\n",
    "            h = self.decoder_latent(z)\n",
    "            h = h.unsqueeze(0).repeat(self.d_n_layers, 1, 1)\n",
    "            w = torch.tensor([c2i['<bos>']] * n_batch, device=self.device())\n",
    "            x = torch.tensor([c2i['<pad>']] * n_batch * max_len, device=self.device()).view(n_batch, max_len)\n",
    "            x[:, 0] = c2i['<bos>']\n",
    "            end_pads = torch.tensor([max_len] * n_batch, device=self.device())\n",
    "            eos_mask = torch.zeros(n_batch, dtype=torch.bool, device=self.device())\n",
    "\n",
    "            for i in range(1, max_len):\n",
    "                w_emb = self.x_emb(w).unsqueeze(1)\n",
    "                x_input = torch.cat([w_emb, z_0], dim=-1)\n",
    "                o, h = self.decoder_rnn(x_input, h)\n",
    "                y = self.decoder_fullyc(o.squeeze(1))\n",
    "                y = F.softmax(y / temp, dim=-1)\n",
    "                w = torch.multinomial(y, 1)[:, 0]\n",
    "                x[:, i] = w\n",
    "                eos_mask = eos_mask | (w == c2i['<eos>'])\n",
    "                if eos_mask.all():\n",
    "                    break\n",
    "\n",
    "            samples = []\n",
    "            for i in range(n_batch):\n",
    "                sample = x[i, :].tolist()\n",
    "                sample_str = ids2string(sample)\n",
    "                samples.append(sample_str)\n",
    "\n",
    "            return samples"
   ],
   "id": "148126d4ce2714de",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:04:25.631068Z",
     "start_time": "2024-10-18T03:04:25.626867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义训练参数\n",
    "n_last = 1000\n",
    "n_batch = 512\n",
    "kl_start = 0\n",
    "kl_w_start = 0.0\n",
    "kl_w_end = 1.0\n",
    "n_epoch = 100\n",
    "n_workers = 0\n",
    "clip_grad = 50\n",
    "lr_start = 0.003\n",
    "lr_n_period = 10\n",
    "lr_n_mult = 1\n",
    "lr_end = 3e-4\n",
    "lr_n_restarts = 6"
   ],
   "id": "c2d3c65065038dbe",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:04:31.528295Z",
     "start_time": "2024-10-18T03:04:31.521320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建损失记录 DataFrame\n",
    "df_losses = pd.DataFrame(columns=['epoch', 'kl_weight', 'lr', 'kl_loss', 'recon_loss', 'loss'])\n"
   ],
   "id": "3919d7a5da4de1be",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:04:37.400230Z",
     "start_time": "2024-10-18T03:04:37.395593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义 KL 权重退火器\n",
    "class KLAnnealer:\n",
    "    def __init__(self, n_epoch):\n",
    "        self.i_start = kl_start\n",
    "        self.w_start = kl_w_start\n",
    "        self.w_max = kl_w_end\n",
    "        self.n_epoch = n_epoch\n",
    "        self.inc = (self.w_max - self.w_start) / (self.n_epoch - self.i_start)\n",
    "\n",
    "    def __call__(self, i):\n",
    "        k = max(0, i - self.i_start)\n",
    "        return self.w_start + k * self.inc"
   ],
   "id": "910ad2d7d4a8f131",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:04:43.170471Z",
     "start_time": "2024-10-18T03:04:43.163766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义带重启的余弦退火学习率调度器\n",
    "class CosineAnnealingLRWithRestart(_LRScheduler):\n",
    "    def __init__(self, optimizer):\n",
    "        self.n_period = lr_n_period\n",
    "        self.n_mult = lr_n_mult\n",
    "        self.lr_end = lr_end\n",
    "        self.current_epoch = 0\n",
    "        self.t_end = self.n_period\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.lr_end + (base_lr - self.lr_end) * \n",
    "                (1 + math.cos(math.pi * self.current_epoch / self.t_end)) / 2\n",
    "                for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "        self.last_epoch = epoch\n",
    "        self.current_epoch += 1\n",
    "\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        if self.current_epoch >= self.t_end:\n",
    "            self.current_epoch = 0\n",
    "            self.t_end *= self.n_mult\n"
   ],
   "id": "afeae7071c7a03d2",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:04:49.064641Z",
     "start_time": "2024-10-18T03:04:49.059890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义循环缓冲区，用于计算平均损失\n",
    "class CircularBuffer:\n",
    "    def __init__(self, size):\n",
    "        self.max_size = size\n",
    "        self.data = np.zeros(self.max_size)\n",
    "        self.size = 0\n",
    "        self.pointer = -1\n",
    "\n",
    "    def add(self, element):\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        self.pointer = (self.pointer + 1) % self.max_size\n",
    "        self.data[self.pointer] = element\n",
    "\n",
    "    def mean(self):\n",
    "        return self.data.mean()"
   ],
   "id": "c513b9f0bcc79a21",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:04:56.383370Z",
     "start_time": "2024-10-18T03:04:56.378608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义日志记录器\n",
    "class Logger(UserList):\n",
    "    def __init__(self, data=None):\n",
    "        super().__init__()\n",
    "        self.sdata = defaultdict(list)\n",
    "        for step in (data or []):\n",
    "            self.append(step)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, int):\n",
    "            return self.data[key]\n",
    "        elif isinstance(key, slice):\n",
    "            return Logger(self.data[key])\n",
    "        else:\n",
    "            return self.sdata[key]\n",
    "\n",
    "    def append(self, step_dict):\n",
    "        super().append(step_dict)\n",
    "        for k, v in step_dict.items():\n",
    "            self.sdata[k].append(v)"
   ],
   "id": "3dbca430f892b418",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:05:56.768151Z",
     "start_time": "2024-10-18T03:05:56.754287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义训练函数\n",
    "# 这个_train_epoch函数可以被其它函数调用，用于训练一个 epoch\n",
    "# 这个_train函数可以被其它函数调用，用于训练整个模型\n",
    "# 这个fit函数可以被其它函数调用，用于训练整个模型\n",
    "def _train_epoch(model, epoch, train_loader, kl_weight, optimizer=None):\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "\n",
    "    kl_loss_values = CircularBuffer(n_last)\n",
    "    recon_loss_values = CircularBuffer(n_last)\n",
    "    loss_values = CircularBuffer(n_last)\n",
    "\n",
    "    for i, input_batch in enumerate(train_loader):\n",
    "        input_batch = [data.to(device) for data in input_batch]\n",
    "        kl_loss, recon_loss = model(input_batch)\n",
    "        loss = kl_weight * kl_loss + recon_loss\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), clip_grad)\n",
    "            optimizer.step()\n",
    "\n",
    "        kl_loss_values.add(kl_loss.item())\n",
    "        recon_loss_values.add(recon_loss.item())\n",
    "        loss_values.add(loss.item())\n",
    "        lr = optimizer.param_groups[0]['lr'] if optimizer is not None else None\n",
    "\n",
    "    kl_loss_value = kl_loss_values.mean()\n",
    "    recon_loss_value = recon_loss_values.mean()\n",
    "    loss_value = loss_values.mean()\n",
    "    postfix = {\n",
    "        'epoch': epoch,\n",
    "        'kl_weight': kl_weight,\n",
    "        'lr': lr,\n",
    "        'kl_loss': kl_loss_value,\n",
    "        'recon_loss': recon_loss_value,\n",
    "        'loss': loss_value,\n",
    "        'mode': 'Eval' if optimizer is None else 'Train'\n",
    "    }\n",
    "    return postfix\n",
    "\n",
    "def _train(model, train_loader, val_loader=None, logger=None):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr_start)\n",
    "    lr_annealer = CosineAnnealingLRWithRestart(optimizer)\n",
    "    kl_annealer = KLAnnealer(n_epoch)\n",
    "    model.zero_grad()\n",
    "\n",
    "    for epoch in tqdm(range(n_epoch), desc='Training', unit='epoch'):\n",
    "        kl_weight = kl_annealer(epoch)\n",
    "        postfix = _train_epoch(model, epoch, train_loader, kl_weight, optimizer)\n",
    "        df_losses.loc[len(df_losses.index)] = [\n",
    "            postfix['epoch'], postfix['kl_weight'], postfix['lr'],\n",
    "            postfix['kl_loss'], postfix['recon_loss'], postfix['loss']\n",
    "        ]\n",
    "        lr_annealer.step()\n",
    "\n",
    "def fit(model, train_data, val_data=None):\n",
    "    logger = Logger()\n",
    "    train_loader = get_dataloader(model, train_data, shuffle=True)\n",
    "    val_loader = None if val_data is None else get_dataloader(model, val_data, shuffle=False)\n",
    "    _train(model, train_loader, val_loader, logger)\n",
    "    return model"
   ],
   "id": "ffeec5402d3d3b5e",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:05:58.142365Z",
     "start_time": "2024-10-18T03:05:58.136131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义数据加载器相关函数\n",
    "# 这get_collate_device函数可以被其它函数调用，用于获取模型所在的设备\n",
    "def get_collate_device(model):\n",
    "    return model.device()\n",
    "\n",
    "# 这get_dataloader函数可以被其它函数调用，用于获取数据加载器\n",
    "def get_dataloader(model, data, collate_fn=None, shuffle=True):\n",
    "    if collate_fn is None:\n",
    "        collate_fn = get_collate_fn(model)\n",
    "    return DataLoader(data, batch_size=n_batch, shuffle=shuffle, num_workers=n_workers, collate_fn=collate_fn)\n",
    "\n",
    "# 这get_collate_fn函数可以被其它函数调用，用于获取数据批次处理函数\n",
    "def get_collate_fn(model):\n",
    "    device = get_collate_device(model)\n",
    "    def collate(batch):\n",
    "        batch.sort(key=len, reverse=True)\n",
    "        tensors = [string2tensor(string, device=device) for string in batch]\n",
    "        return tensors\n",
    "    return collate"
   ],
   "id": "6d66dd7dde272540",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:06:03.581683Z",
     "start_time": "2024-10-18T03:06:03.577828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 这get_optim_params函数可以被其它函数调用，用于获取可训练参数\n",
    "def get_optim_params(model):\n",
    "    return (p for p in model.parameters() if p.requires_grad)\n"
   ],
   "id": "f54d1549dde9fbc0",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:06:08.622691Z",
     "start_time": "2024-10-18T03:06:08.617793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义采样函数\n",
    "class Sample:\n",
    "    @staticmethod\n",
    "    def take_samples(model, n_batch, n_samples=1000, max_len=100):\n",
    "        n = n_samples\n",
    "        samples = []\n",
    "        with tqdm(total=n_samples, desc='Generating samples') as T:\n",
    "            while n > 0:\n",
    "                current_samples = model.sample(min(n, n_batch), max_len)\n",
    "                samples.extend(current_samples)\n",
    "                n -= len(current_samples)\n",
    "                T.update(len(current_samples))\n",
    "        samples = pd.DataFrame(samples, columns=['SMILES'])\n",
    "        return samples"
   ],
   "id": "d9f03715fd1539fa",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:06:13.227237Z",
     "start_time": "2024-10-18T03:06:13.181821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始化模型\n",
    "model = VAE(vocab, vector).to(device)"
   ],
   "id": "5cd62bbcb69314ae",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-18T03:06:44.119348Z",
     "start_time": "2024-10-18T03:06:17.300089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练模型\n",
    "fit(model, train_data)"
   ],
   "id": "82a2e719897b0bfa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:00<?, ?epoch/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 保存模型\n",
    "import os\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "torch.save(model.state_dict(), f'checkpoints/vae_model_epoch{n_epoch}.pt')"
   ],
   "id": "ffe08e7515c75691"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 加载模型（如果需要）\n",
    "# model.load_state_dict(torch.load(f'checkpoints/vae_model_epoch{n_epoch}.pt'))\n"
   ],
   "id": "f907a78e73c9fedd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 生成样本\n",
    "model.eval()\n",
    "df_sample = Sample.take_samples(model, n_batch)\n",
    "print(df_sample)"
   ],
   "id": "c379d40145108198"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 保存生成的分子\n",
    "os.makedirs('generated_molecules/vae', exist_ok=True)\n",
    "df_sample.to_csv(f'generated_molecules/vae/vae_epoch{n_epoch}.csv', index=False)"
   ],
   "id": "fc13b7c529ff1ef3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 保存损失值\n",
    "os.makedirs('checkpoints/losses', exist_ok=True)\n",
    "df_losses.to_csv(f'checkpoints/losses/vae_epoch{n_epoch}.csv', index=False)"
   ],
   "id": "766f4a0451e49df2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制损失值图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(df_losses, title):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(df_losses['epoch'], df_losses['kl_loss'], label='KL loss')\n",
    "    plt.plot(df_losses['epoch'], df_losses['recon_loss'], label='Recon loss')\n",
    "    plt.plot(df_losses['epoch'], df_losses['loss'], label='Total loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(df_losses, f'VAE (epoch {n_epoch})')"
   ],
   "id": "62081ee05719fc0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制生成的分子\n",
    "import rdkit\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "def plot_molecules(df_sample, n_rows=10, n_cols=10):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i, smiles in enumerate(df_sample['SMILES']):\n",
    "        mol = rdkit.Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            plt.subplot(n_rows, n_cols, i+1)\n",
    "            Draw.MolToImage(mol)\n",
    "            plt.title(smiles)\n",
    "    plt.show()\n",
    "\n",
    "plot_molecules(df_sample, n_rows=10, n_cols=10) # 绘制前 1000 个分子"
   ],
   "id": "f02dc0a54df6442"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制训练过程中的 KL 权重\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_losses['epoch'], df_losses['kl_weight'], label='KL weight')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('KL weight')\n",
    "plt.title(f'VAE (epoch {n_epoch})')\n",
    "plt.legend()\n",
    "plt.show()  "
   ],
   "id": "47c94dc29d05478f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制训练过程中的学习率\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_losses['epoch'], df_losses['lr'], label='Learning rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.title(f'VAE (epoch {n_epoch})')\n",
    "plt.legend()\n",
    "plt.show()  "
   ],
   "id": "f99c14614445b627"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制训练过程中的 KL 损失\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_losses['epoch'], df_losses['kl_loss'], label='KL loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('KL loss')\n",
    "plt.title(f'VAE (epoch {n_epoch})')\n",
    "plt.legend()\n",
    "plt.show()  "
   ],
   "id": "acb9dbfc10fcc5fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制训练过程中的重构损失\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_losses['epoch'], df_losses['recon_loss'], label='Recon loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recon loss')\n",
    "plt.title(f'VAE (epoch {n_epoch})')\n",
    "plt.legend()\n",
    "plt.show()  "
   ],
   "id": "c72d308dd85d74e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制训练过程中的总损失\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_losses['epoch'], df_losses['loss'], label='Total loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total loss')\n",
    "plt.title(f'VAE (epoch {n_epoch})')\n",
    "plt.legend()\n",
    "plt.show()      "
   ],
   "id": "f2c782f2aeb590f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制训练过程中的 KL 权重与学习率\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_losses['epoch'], df_losses['kl_weight'], label='KL weight')\n",
    "plt.plot(df_losses['epoch'], df_losses['lr'], label='Learning rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Weight/Learning rate')  \n",
    "plt.title(f'VAE (epoch {n_epoch})')\n",
    "plt.legend()\n",
    "plt.show()  "
   ],
   "id": "ba148b5bf30327fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制训练过程中的 KL 损失与重构损失\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_losses['epoch'], df_losses['kl_loss'], label='KL loss')\n",
    "plt.plot(df_losses['epoch'], df_losses['recon_loss'], label='Recon loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('KL/Recon loss')  \n",
    "plt.title(f'VAE (epoch {n_epoch})')\n",
    "plt.legend()\n",
    "plt.show()  "
   ],
   "id": "d5b3b5f25f242663"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 绘制训练过程中的 KL 损失、重构损失与总损失\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df_losses['epoch'], df_losses['kl_loss'], label='KL loss')\n",
    "plt.plot(df_losses['epoch'], df_losses['recon_loss'], label='Recon loss')\n",
    "plt.plot(df_losses['epoch'], df_losses['loss'], label='Total loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')  \n",
    "plt.title(f'VAE (epoch {n_epoch})')\n",
    "plt.legend()\n",
    "plt.show()  "
   ],
   "id": "2cd940c157cc9f24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
